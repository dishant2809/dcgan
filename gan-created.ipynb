{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom glob import glob\nimport cv2\nfrom skimage.transform import resize\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten,Conv2D,Reshape,Dense,Conv2DTranspose,BatchNormalization,LeakyReLU,Add,Activation,Input\nfrom tensorflow.keras.optimizers import SGD, Adam","metadata":{"id":"BOzeFIjdmlZY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_h = 128\nimg_w = 128\nimg_c = 3\nd = img_h,img_w,img_c","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_model(img_size):\n    \n    i = Input(shape=(128,128,3))\n    \n    x = Flatten()(i)\n\n    x = Dense(1024,activation=LeakyReLU())(x)\n    \n    x = Dense(512,activation=LeakyReLU())(x)\n    \n    x = Dense(256,activation=LeakyReLU())(x)\n    \n    x = Dense(1,activation='sigmoid')(x)\n    \n    model = Model(i,x)\n    return model\n","metadata":{"id":"lKVVej-LmlV3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlatent_dim = 100\n\ndef generator_model():\n    \n    i = Input(shape=(latent_dim,))\n    x = Dense(8*8*256, use_bias=False, input_shape=(100,))(i)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n\n    x = Reshape((8, 8, 256))(x)\n\n    x = Conv2DTranspose(128, (5, 5), strides=(2,2), padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False,)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n    \n    model = Model(i,x)\n\n    return model\n\n    \n    \n    \n#     i = Input(shape = latent_dim,)\n#     x = Dense(256,activation=LeakyReLU())(i)\n#     x = BatchNormalization()(x)\n    \n#     x = Dense(512,activation=LeakyReLU())(x)\n#     x = BatchNormalization()(x)\n    \n#     x = Dense(1024,activation=LeakyReLU())(x)\n#     x = BatchNormalization()(x)\n    \n# #     x = Conv2D(,kernel_size=1,activation='tanh')(x)\n# #     x = Reshape((128,128,3))(x)\n   \n    \n#     model = Model(i,x)\n\n#     return model\n","metadata":{"id":"SyuenhcnmlSW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = discriminator_model(d)\ndiscriminator.compile( loss='binary_crossentropy', optimizer= discriminator_optimizer , metrics=['accuracy'])\n\ngenerator = generator_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/animals/images/butterfly'\nlist_img = sorted(os.listdir(path))","metadata":{"id":"5OAggX6GmlOx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg = []\nfor i in list_img:\n    a = cv2.imread(path+'/'+i)\n    a = cv2.cvtColor(a,cv2.COLOR_RGB2BGR)\n    a = cv2.resize(a,(img_h,img_w))\n    img.append(a)\n    \n\nimg = np.array(img)\n# img = img / 255.0 * 2 - 1\n# img = img.reshape(-1,d)\nprint(img.shape)\n\n# ***************************************************************************************\n# img = []\n# for i in list_img:\n#     a = path+'/'+i\n#     b = os.listdir(a)\n#     for j in b:\n#         fnl_pth = cv2.imread(a+'/'+j)\n#         fnl_pth = cv2.cvtColor(fnl_pth,cv2.COLOR_RGB2BGR)\n#         fnl_pth = cv2.resize(fnl_pth,(img_h,img_w))\n#         img.append(fnl_pth)\n\n# img = np.array(img)\n# print(img.shape)","metadata":{"id":"iGMzDMPGmlKb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img[655])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z = Input(shape=(latent_dim,))\nprint(z.shape)\n\ngen = generator(z)\nprint(gen.shape)\n\ndiscriminator.trainable = False\n\nfake_pred = discriminator(gen)\n\ncombined_model = Model(z, fake_pred)\n\ncombined_model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))","metadata":{"id":"CxauVTcimkrD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 10000 + 1\nsample_period = 1000","metadata":{"id":"4XDa7RQupy_8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zeros = np.zeros(batch_size)\nones = np.ones(batch_size)\n\nd_losses = []\ng_losses = []\n\nif not os.path.exists('gan_img'):\n    os.makedirs('gan_img')","metadata":{"id":"PipRDEy_XXii","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample_images(epoch):\n  rows, cols = 2, 2\n  noise = np.random.randn(rows * cols, latent_dim)\n  imgs = generator.predict(noise)\n\n  # Rescale images 0 - 1\n  imgs = 0.5 * imgs + 0.5\n\n  fig, axs = plt.subplots(rows, cols)\n  idx = 0\n  for i in range(rows):\n    for j in range(cols):\n      axs[i,j].imshow(imgs[idx].reshape(img_h, img_w,img_c), cmap='gray')\n      axs[i,j].axis('off')\n      idx += 1\n  fig.savefig(\"gan_img/%d.png\" % epoch)\n  plt.close()","metadata":{"id":"neNS-rJvXXly","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint_dir = './training_checkpoints'\n# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n# checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n#                                  discriminator_optimizer=discriminator_optimizer,\n#                                  generator=generator,\n#                                  discriminator=discriminator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor epoch in range(epochs):\n      \n    idx = np.random.randint(0, img.shape[0], batch_size)\n    real_imgs = img[idx]\n    \n    \n    noise = np.random.randn(batch_size, latent_dim)\n    fake_imgs = generator.predict(noise)\n    \n    \n    d_loss_real, d_acc_real = discriminator.train_on_batch(real_imgs, ones)\n    d_loss_fake, d_acc_fake = discriminator.train_on_batch(fake_imgs, zeros)\n\n    d_loss = 0.5 * (d_loss_real + d_loss_fake)\n    d_acc  = 0.5 * (d_acc_real + d_acc_fake)\n    \n    noise = np.random.randn(batch_size, latent_dim)\n    g_loss = combined_model.train_on_batch(noise, ones)\n    \n    \n    noise = np.random.randn(batch_size, latent_dim)\n    g_loss = combined_model.train_on_batch(noise, ones)\n    \n    \n    d_losses.append(d_loss)\n    g_losses.append(g_loss)\n    \n    if epoch % 100 == 0:\n      print(f\"epoch: {epoch+1}/{epochs}, d_loss: {d_loss:.2f}, \\\n        d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}\")\n    \n    if epoch % sample_period == 0:\n      sample_images(epoch)\n    \n#     if epoch  == (epochs/2):\n#         generator.save('generator{}.h5'.format(epoch))\n    \n    \n#     if epochs == epoch:\n#         generator.save('generator{}.h5'.format(epoch))\n#         combined_model.save('combined_model.h5')\n#         discriminator.save('discriminator.h5')\n    ","metadata":{"id":"Q9gjZ-O0XXpa","outputId":"d3bbec7d-bd24-4cf6-ebe2-4454d56caed7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.save('generator.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import load_model\nfrom numpy import asarray\nimport matplotlib.pyplot as plt\nfrom numpy.random import randn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_c = load_model('../input/generator/generator (1).h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vector =  np.random.randn(1, 100) #Vector of random numbers (creates a column, need to reshape)\n# vector = vector.reshape(1, 100)\n\n# generate image\nX = model_c.predict(vector)\n\n# plot the result\nplt.imshow(X[0],cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combined_model.save('cm.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = cv2.imread('./gan_img/{}.png'.format(220000))\nplt.imshow(a)","metadata":{"id":"7lxYeDyWXXtK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}